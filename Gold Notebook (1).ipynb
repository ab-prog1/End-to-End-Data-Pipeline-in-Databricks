{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2814a715-c99d-4442-bc67-c7abce980f68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Mount ADLS Gen2\n",
    "#Required each time the cluster is restarted which should be only on the first notebook as they run in order\n",
    "\n",
    "tiers = [\"bronze\", \"silver\", \"gold\"]\n",
    "adls_paths = {tier: f\"abfss://{tier}@rgdatabricksaccount.dfs.core.windows.net/\" for tier in tiers}\n",
    "\n",
    "# Accessing paths\n",
    "bronze_adls = adls_paths[\"bronze\"]\n",
    "silver_adls = adls_paths[\"silver\"]\n",
    "gold_adls = adls_paths[\"gold\"]\n",
    "\n",
    "silver_data = f\"{silver_adls}earthquake_events_silver/\"\n",
    "\n",
    "dbutils.fs.ls(bronze_adls)\n",
    "dbutils.fs.ls(silver_adls)\n",
    "dbutils.fs.ls(gold_adls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae4c813d-fb05-474a-aaaa-28c7426a64df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "start_date = date.today() - timedelta(1)\n",
    "end_date = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8c8d651-ca9e-4db4-a913-19f2882996a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Date: , Gold ADLS: \n"
     ]
    }
   ],
   "source": [
    "# Retrieve the task value from the previous task (bronze & silver)\n",
    "bronze_output = dbutils.jobs.taskValues.get(taskKey=\"Bronze\", key=\"bronze_output\", debugValue={})\n",
    "silver_output = dbutils.jobs.taskValues.get(taskKey=\"silver\", key=\"silver_output\", debugValue={})\n",
    "\n",
    "# Access individual variables\n",
    "start_date = bronze_output.get(\"start_date\", \"\")\n",
    "silver_adls = bronze_output.get(\"silver_adls\", \"\")\n",
    "gold_adls = bronze_output.get(\"gold_adls\", \"\")\n",
    "\n",
    "print(f\"Start Date: {start_date}, Gold ADLS: {gold_adls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64532faa-db36-40fd-b862-68f602f7f028",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import  when, col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "# Ensure the below library is installed on your cluster\n",
    "import reverse_geocoder as rg\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d09bb61-f8be-4a25-a93d-4532d58ed429",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "df = spark.read.parquet(silver_data).filter(col(\"time\") > start_date)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0656914a-16cb-4405-995b-8674d4d9331c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Limit the DataFrame to speed up processing as during testing it was proving a bottleneck\n",
    "df = df.limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c485d02-fa56-472e-8a55-2b0f36de2e31",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_country_code(lat, lon):\n",
    "    \"\"\"\n",
    "    Retrieve the country code for a given latitude and longitude.\n",
    "\n",
    "    Parameters:\n",
    "    lat (float): Latitude of the location.\n",
    "    lon (float): Longitude of the location.\n",
    "\n",
    "    Returns:\n",
    "    str: Country code of the location, retrieved using the reverse geocoding API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Processed coordinates\n",
    "        coordinates = (float(lat), float(lon))\n",
    "        result = rg.search(coordinates) [0].get('cc')\n",
    "        print(\"Processed coordinates: {coordinates} -> {result}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing coordinates: (lat: {lat}, lon: {lon}) -> {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9decfa98-5eab-4f2c-b330-3802460182a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "get_country_code_udf = udf(get_country_code, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d47630e5-1ab2-4840-a908-562773c214d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed coordinates: {coordinates} -> {result}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'FR'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_country_code(48.858443, 2.294536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29d9740c-f9d1-40cc-aa44-fc834399c7f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Adding country_code and city attributes\n",
    "df_with_location = \\\n",
    "     df.\\\n",
    "          withColumn(\"country_code\", get_country_code_udf(col(\"latitude\"), col(\"longitude\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "618d1558-abd8-486a-bb45-3cb5d5ddefe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Adding significance classification\n",
    "df_with_location_sig_class =\\\n",
    "    df_with_location.\\\n",
    "    withColumn(\"sig_class\", \n",
    "        when(col(\"sig\") < 100, \"Low\").\\\n",
    "        when((col(\"sig\") >= 100) & (col(\"sig\") < 500), \"Moderate\").\\\n",
    "        otherwise(\"High\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6f277d2-cd50-4e14-ab65-f3ec3dc31390",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_with_location_sig_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dbed463-880a-45df-b69e-34c7f628a8da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the output path for the Silver container\n",
    "#gold_output_path = f\"{gold_adls}/earthquake_events_gold/\"\n",
    "gold_output_path = \"abfss://gold@rgdatabricksaccount.dfs.core.windows.net/earthquake_events_gold/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3dde26a-5175-4aed-adbc-ef844bdd619b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Append DataFrame to Silver container in Parquet format\n",
    "df_with_location_sig_class.write.mode(\"append\").parquet(gold_output_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold Notebook",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}